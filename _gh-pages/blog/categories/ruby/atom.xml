<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: ruby | Artsy Engineering]]></title>
  <link href="http://artsy.github.io/blog/categories/ruby/atom.xml" rel="self"/>
  <link href="http://artsy.github.io/"/>
  <updated>2017-09-10T21:04:34-04:00</updated>
  <id>http://artsy.github.io/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Using OCR To Fix a Hilarious Bug]]></title>
    <link href="http://artsy.github.io/blog/2015/11/04/Using-OCR-To-Fix-A-Hilarious-Bug/"/>
    <updated>2015-11-04T19:00:00-05:00</updated>
    <id>http://artsy.github.io/blog/2015/11/04/Using-OCR-To-Fix-A-Hilarious-Bug</id>
    <content type="html"><![CDATA[<p>For a little while, we would get very strange bug reports. People would complain that artist thumbnails (viewed in several different contexts across the web and our iOS apps) would not be an image of the artist's work, but rather text, which had inexplicably become an actual JPG. This wasn't just text appearing in a <code>div</code> that should contain an <code>img</code> or something like that, these were actual JPG's that were pictures of text.</p>

<p>We would fix these as they came up, chalking the strangeness up to some relic of an old image processing pipeline, data being migrated, etc.</p>

<p>However, the reports kept coming in. This blog post is about how we diagnosed this actual bug, and how we used a simple Ruby script and OCR to help us detect and fix the existing images.</p>

<!-- more -->


<p>Here's an example of a bug report where the thumbnail for <a href="https://www.artsy.net/artist/marina-abramovic-1">Marina AbramoviÄ‡</a> became the text of her bio.</p>

<p><img src="/images/2015-11-12-hilarious-bug/search.png" alt="Bad Search" /></p>

<p>Here's one from our <a href="https://github.com/artsy/eigen">iOS app</a> showing that thumbnails for related artists are set to their bios as well.</p>

<p><img src="/images/2015-11-12-hilarious-bug/eigen.png" alt="Bad Related Artists" /></p>

<p>Weird right? We eventually tracked down what was going on, and it's actually perfectly summarized in <a href="https://github.com/blueimp/jQuery-File-Upload/pull/3356">this issue</a>. When someone copies text from Excel, it also generates an image of that cell or cells, and puts it into the clipboard. We immediately suspected something with <code>pasteZone</code>, and the bug was easy to reproduce - have an image in your clipboard and paste anywhere on the page.</p>

<p>We have an admin panel that allows some metadata about an artist to be edited. This includes their bio, as well as a place to upload a representative image as their 'cover thumbnail'.</p>

<p>As the issue describes, we had some text input fields, as well as a file upload form using <a href="https://github.com/blueimp/jQuery-File-Upload">Blueimp's jQuery File Upload</a>. When you don't specify a <code>pasteZone</code> it defaults to the entire document. This means that a paste event anywhere on the page will trigger that event.</p>

<p>Our editorial team was using Microsoft Excel and Word to organize some data about the artist, including bios. When ready, a team member would copy and paste the bio into the bio input text field. This would also immediately fire the event for the image upload, which now automagically became an actual picture of the text of the bio. Our API and image processing pipeline would happily accept that, leading to the incredibly bizarre bug reports.</p>

<p>My immediate fix was to specify and scope <code>pasteZone</code> (and similarly, <code>dropZone</code>) to the element the file upload widget was bound to. That would prevent the problem from happening again. Taking a quick look art some random samples of artists, it looked like potentially thousands of records might have been affected and I became interested in a programmatic way to detect these images. A manual approach would have been very cumbersome.</p>

<p>Since the images were that of text, I decided to use OCR to remove artist thumbnails that it determined had 'too much text'. This may have unset valid covers from artists that use lots of text in their work, such as <a href="https://www.artsy.net/artist/joseph-kosuth">Joseph Kosuth</a>. However, this was safe to do since we have some custom logic to fall back to an image of an iconic artwork by the artist in the case of a missing thumbnail.</p>

<p>To get OCR functionality in Ruby, I decided to use <a href="https://github.com/tesseract-ocr/tesseract">Tesseract</a>, a great OSS library. Once I had it installed, I used a <a href="https://github.com/meh/ruby-tesseract-ocr">ruby wrapper</a> to make using it easier.</p>

<p>The script eventually turned into something like:</p>

<pre><code class="ruby"># initialize and configure Tesseract
engine = Tesseract::Engine.new do |config|
  config.language  = :eng
  config.blacklist = '|'
end

# iterate over artists and pull their thumbnails
# given the URL to a publicly accessible image at img

text = engine.text_for(img)
text = text.gsub(/[^a-z ]/i, '').gsub(' ', '')
if text.length &gt; 30
  puts "Found problematic artist #{artist_doc['last']}"
  # ...
end
</code></pre>

<p>So all we do is find all the text in an image, and then remove any garbage characters or artifacts from the OCR analysis, and then use 30 as an arbitrary cutoff to determine if an image was problematic. If the image had more than 30 characters as detected by the OCR library, we wound up unsetting it from the artist.</p>

<p>The additional logic to set artist covers from their iconic artworks was already in place, and I ran this script in production, identifying and unsetting over 1000 problematic thumbnails. And we haven't gotten any new reports of this bug since then :)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Splitting up a large test suite]]></title>
    <link href="http://artsy.github.io/blog/2015/09/24/splitting-up-a-large-test-suite/"/>
    <updated>2015-09-24T22:13:00-04:00</updated>
    <id>http://artsy.github.io/blog/2015/09/24/splitting-up-a-large-test-suite</id>
    <content type="html"><![CDATA[<p>A while back, we wrote about <a href="/blog/2012/10/09/how-to-run-rspec-test-suites-in-parallel-with-jenkins-ci-build-flow/">How to Run RSpec Test Suites in Parallel with Jenkins CI Build Flow</a>. A version of that still handles our largest test suite, but over time the initial division of specs became unbalanced. We ended up with some tasks that took twice as long as others. Even worse, in an attempt to rebalance task times, we ended up with awkward file patterns like <code>'spec/api/**/[a-m]*_spec.rb'</code>.</p>

<p>To keep our parallel spec tasks approximately equal in size and to support arbitrary concurrency, we've added a new <code>spec:sliced</code> task:</p>

<!-- more -->


<pre><code class="ruby">namespace :spec do
  task :set_up_spec_files do
    spec_files = Dir['spec/**/*_spec.rb']
    @spec_file_digests = Hash[spec_files.map { |f| [f, Zlib.crc32(f)] }]
  end

  RSpec::Core::RakeTask.new(:sliced, [:index, :concurrency] =&gt; :set_up_spec_files) do |t, args|
    index = args[:index].to_i
    concurrency = args[:concurrency].to_i
    t.pattern = @spec_file_digests.select { |f, d| d % concurrency == index }.keys
  end
end
</code></pre>

<p>As you can see, the <code>set_up_spec_files</code> helper task builds a hash of spec file paths and corresponding checksums. When we invoke the <code>sliced</code> task with <code>index</code> and <code>concurrency</code> values (e.g., <code>0</code> and <code>5</code>), only the spec files with checksums equal to <code>0</code> when mod-ed by <code>5</code> are run. Thus, the Jenkins build flow would look like:</p>

<pre><code class="java">parallel (
  {build("master-ci-task", tasks: "spec:sliced[0,5]")},
  {build("master-ci-task", tasks: "spec:sliced[1,5]")},
  {build("master-ci-task", tasks: "spec:sliced[2,5]")},
  {build("master-ci-task", tasks: "spec:sliced[3,5]")},
  {build("master-ci-task", tasks: "spec:sliced[4,5]")}
)
build("master-ci-succeeded")
</code></pre>

<p>Now, spec times <em>might</em> continue to be unbalanced despite files being split up approximately evenly. (For a more thorough approach based on recording spec times, see <a href="https://github.com/ArturT/knapsack">knapsack</a>.) However, this little bit of randomness was a big improvement over our previous approach, and promises to scale in a uniform manner.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Releasecop Tracks Stale Releases]]></title>
    <link href="http://artsy.github.io/blog/2015/09/01/releasecop-tracks-stale-releases/"/>
    <updated>2015-09-01T17:30:00-04:00</updated>
    <id>http://artsy.github.io/blog/2015/09/01/releasecop-tracks-stale-releases</id>
    <content type="html"><![CDATA[<p>Artsy practices a sort of <a href="http://en.wikipedia.org/wiki/Continuous_delivery">continuous delivery</a>. We keep release cycles short and the process of reviewing, testing, and deploying our software as reliable, fast, and automated as possible. (This blog has touched on these practices <a href="http://artsy.github.io/blog/categories/testing/">multiple</a> <a href="http://artsy.github.io/blog/categories/continuous-integration">times</a>.)</p>

<p>Usually, commits that have been reviewed and merged are immediately built and tested. Successfully built versions of the codebase are often automatically deployed to a staging environment. On an automated or frequent-but-manual basis, that version is deployed to a production environment. Thus, commits form a pipeline:</p>

<ul>
<li>From developers' working branches</li>
<li>To the master branch</li>
<li>Through a hopefully-successful build</li>
<li>To a staging environment</li>
<li>To production</li>
</ul>


<p>The number of apps and services we deploy has grown to <em>dozens</em> per team, so sometimes things fall through the cracks. We've been using <a href="https://github.com/joeyAghion/releasecop">Releasecop</a> for the last few months to get gentle email reminders when an environment could use a deploy.</p>

<!-- more -->


<pre><code>gem install releasecop
releasecop edit
</code></pre>

<p>This opens a <em>manifest</em> file where you can describe the sequence of git remotes and branches that make up your own release pipeline. For example:</p>

<pre><code>{
  "projects": {
    "charge": [
      { "name": "master", "git": "git@github.com:artsy/charge.git" },
      { "name": "staging", "git": "git@heroku.com:charge-staging.git" },
      { "name": "production", "git": "git@heroku.com:charge-production.git" }
    ],
    "gravity": [
      { "name": "master", "git": "git@github.com:artsy/gravity.git" },
      { "name": "master-succeeded", "git": "git@github.com:artsy/gravity.git", "branch": "master-succeeded" },
      { "name": "staging", "git": "git@github.com:artsy/gravity.git", "branch": "staging" },
      { "name": "production", "git": "git@github.com:artsy/gravity.git", "branch": "production" }
    ]
  }
}
</code></pre>

<p>The <code>charge</code> app is a typical deployment to Heroku. Work progresses from the <code>master</code> branch to a <code>charge-staging</code> app to a <code>charge-production</code> app. The <code>gravity</code> app is a more complicated, non-Heroku deployment. It updates git branches to reflect what has been merged (<code>master</code>), tested (<code>master-succeeded</code>), deployed to staging, and deployed to production.</p>

<p>Run the <code>releasecop check [app]</code> command to report the status of your apps' releases:</p>

<pre><code>$ releasecop check --all
charge...
  staging is up-to-date with master
  production is up-to-date with staging
gravity...
  master-succeeded is up-to-date with master
  staging is up-to-date with master-succeeded
  production is behind staging by:
    06ca969 2015-09-04 [config] Replace Apple Push Notification certificates that expire today. (Eloy DurÃ¡n)
    171121f 2015-09-03 Admin-only API for cancelling a bid (Matthew Zikherman)
    4c5feea 2015-09-02 install mongodb client in Docker so that import rake tasks can run (Barry Hoggard)
    95347d1 2015-08-31 Update to delayed_job cookbook that works with Chef 11.10 (Joey Aghion)
2 project(s) checked. 1 environment(s) out-of-date.
</code></pre>

<p>A nightly <a href="https://jenkins-ci.org/">Jenkins</a> job emails us the results, but a cron job could work equally well.</p>

<p><a href="https://github.com/joeyAghion/releasecop">Releasecop</a> reminds us to deploy ready commits and close the loop on in-progress work. We hope you find it useful. (Pull requests are welcome!)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Generating Notifications and Personalized Emails Efficiently]]></title>
    <link href="http://artsy.github.io/blog/2014/04/24/generating-notifications-and-personalized-emails-efficiently/"/>
    <updated>2014-04-24T16:00:00-04:00</updated>
    <id>http://artsy.github.io/blog/2014/04/24/generating-notifications-and-personalized-emails-efficiently</id>
    <content type="html"><![CDATA[<p>We recently launched a new personalized email here at <a href="https://artsy.net">Artsy</a> that features content that a given user might find interesting. The goal of this post is to describe how we built a backend system that efficiently generates these e-mails for all our users. I'll talk about the first, naive implementation that had performance problems right away, and how the second implementation (currently in production) solved those issues, and whose behavior at scale is well-defined and understood. I won't go into the details of the design and layout of the mail itself and how we render the content - there are several earlier blog posts that deal with those: <a href="http://artsy.github.io/blog/2014/03/18/presenters-and-memoization-moving-logic-out-of-templates/">Presenters and Memoization</a>, <a href="http://artsy.github.io/blog/2014/03/17/ruby-helper-to-group-artworks-into-a-pinterest-style-layout-for-email/">Pinterest-style Layouts</a> and <a href="http://artsy.github.io/blog/2014/03/17/some-tips-for-email-layout-and-responsiveness/">Email Layouts and Responsiveness</a>.</p>

<p><img src="/images/2014-04-24-generating-notifications-and-personalized-emails-efficiently/percy_example.png" alt="Personalized Email Example" /></p>

<!-- more -->


<a name="Deciding.What.Content.to.Include"></a>
<h3>Deciding What Content to Include</h3>

<p>First, we had to decide what types of personalized content we wanted to feature in our mails. Users can follow artists and galleries, and so this seemed like a great place to start. We'd like to let you know about new artworks that have been uploaded by artists that you follow, as well as new shows that have been added by galleries you follow, or that are exhibiting artists you follow. Since we have location data for our galleries and our users (accomplished thru an onboarding flow, or thru geo-locating their IP address), we also want to include new shows that are opening near you. Additionally, we have a recommendations engine that recommends artworks to users based on their preferences and activity on the site, and we'd like to show some of the latest and best of such recommendations.</p>

<a name="Initial.Implementation.Ideas"></a>
<h3>Initial Implementation Ideas</h3>

<p>My first thought was to have an observer (really just some <code>after_save</code> callbacks) that will wait for data to get into a state where a user can be validly notified, and in a background task write these notifications to interested users. Here's how the base setup of our <code>Notification</code> model looked:</p>

<pre><code class="ruby">class Notification
  include Mongoid::Document
  include Mongoid::Timestamps

  belongs_to :user
  belongs_to :notifiable, polymorphic: true, inverse_of: :notifications
end
</code></pre>

<p>It's a simple join of the user and the <code>notifiable</code> (the object/action that a user is being notified about).</p>

<p>Then, a specific notification (such as one for published artworks by artists you follow) can inherit from this and look like:</p>

<pre><code class="ruby">class PublishedArtworkNotification &lt; Notification
  def self.notify!(artwork_id)
    user_ids = FollowArtist.where(artist: artwork.artist).pluck("user_id")
    user_ids.each_slice(100) do |uids|
      PublishedArtworkNotification.delay(queue: :any, priority: 6).create_for_users(artwork_id, uids)
    end
  end

  def self.create_for_users(artwork, uids)
    uids.each do |uid|
      PublishedArtworkNotification.create!(user_id: uid, notifiable_id: artwork_id, notifiable_type: 'Artwork')
    end
  end
end
</code></pre>

<p>Then, the <code>after_save</code> hook on an <code>Artwork</code> model is:</p>

<pre><code class="ruby">def delay_notify
  PublishedArtworkNotification.delay(queue: :any).notify!(self.id) if self.published_changed? &amp;&amp; self.published
end
</code></pre>

<p>So, when an artwork is published, we run <code>notify!</code> in the background for the respective notification. That method will pull all interested users (via following the artist), and then spawn off more background processes to write the notifications in batches of 100. We batched these writes to avoid any one background process taking too long (an artist such as <a href="https://artsy.net/artist/andy-warhol">Andy Warhol</a> has around twelve thousand followers currently), and also ran them at a lower priority to avoid blocking other jobs in our queue.</p>

<p>The other types of notifications were all implemented similarly (via an observer on the model, and a specific <code>Notification</code> class inheriting from the base class). We also added some other logic into the base <code>Notification</code> class such as some uniqueness constraints, as well as an ability to mark notifications as 'sent' or 'invalid'. However, we ran into serious performance/scaling issues fairly quickly, and had to re-implement this scheme.</p>

<a name="Performance.Bottlenecks"></a>
<h3>Performance Bottlenecks</h3>

<p>All of these records were being written to one collection in <a href="https://www.mongodb.org/">MongoDB</a>, and the size of this collection grew quite rapidly. It's size almost immediately dwarfed the size of any of our other collections, and the number of records quickly reached into the tens of millions. This led to problems: writing new notifications started to crawl to a standstill. We had several indices on this collection to aid in querying, and these made the insertion of new notifications very non-performant, and also started to affect overall database performance. Querying against this collection degraded quickly and started to similarly affect database performance. Archiving old records also proved next to impossible. We couldn't simply drop the entire collection, but had to prune records. This similarly was totally non-performant and was adversely affecting database and site performance. We needed to come up with a new implementation for <code>Notification</code>, and addressing these issues was essential.</p>

<a name="Resolving.Performance.Bottlenecks"></a>
<h3>Resolving Performance Bottlenecks</h3>

<p>So, we decided on a scheme where each day would result in a new <code>Notifications</code> collection (name keyed on the date), named <code>notifications_20140101</code>, <code>notifications_20140102</code>, etc. Each of these collections would have an <code>_id</code> field that corresponds to a user_id, and an <code>events</code> array (or 'stack' if you will) that records the id's of notified objects, as well as the type of notification. An example of a record in that collection is:</p>

<pre><code class="json">{"_id"=&gt;"5106b619f56337db300001f8",
 "events"=&gt;[{"t"=&gt;"NearbyShow", "o"=&gt;"533998b1c9dc24c371000041"},
            {"t"=&gt;"NearbyShow", "o"=&gt;"5345774cc9dc246d580003d0"},
            {"t"=&gt;"NearbyShow", "o"=&gt;"5335af4fa09a67145300028c"},
            {"t"=&gt;"NearbyShow", "o"=&gt;"533f1174a09a67298900007b"},
            {"t"=&gt;"ArtworkPublished", "o"=&gt;"5334647b139b2165160000d8"}]
}
</code></pre>

<p>So, here we see all of my notifications for April 22, 2014. On that day, I was notified about 4 shows opening near my location, and one artwork added by an artist I follow. Incidentally, that artwork was a piece by <a href="https://artsy.net/artist/rob-wynne">Rob Wynne</a> entitled <a href="https://artsy.net/artwork/rob-wynne-youre-dreaming">You're Dreaming</a>. The show notifications were for NYC-area shows opening at <a href="https://artsy.net/klein-sun-gallery">Klein Sun Gallery</a>, <a href="https://artsy.net/garis-and-hahn">Garis &amp; Hahn</a>, <a href="https://artsy.net/miyako-yoshinaga-gallery">Miyako Yoshinaga Gallery</a> and <a href="https://artsy.net/dodgegallery">DODGEgallery</a>.</p>

<p>A couple of nice things about this implementation is it limits the size of a collection: any one day's collection will scale directly with the number of users, which seems reasonable. Our earlier implementation scaled with the product of the number of users and amount of content on Artsy, which is clearly problematic. Also, archiving old notifications is as simple as dropping a particular day's collection, which is very performant. However, querying and assembling these notifications is a bit trickier than in the naive implementation, as well as marking which events have already been sent to a user, so as to avoid duplicating any content in between mailings.</p>

<p>Let's see how we rewrite the notification generation in this scheme:</p>

<pre><code class="ruby">module NotificationService

  def self.notify_many!(user_ids, object_id, type)
    events = events_from(object_id, type)
    user_ids.each do |user_id|
      notify_with_events(user_id, events)
    end
  end

  private

  def self.notify_with_events(user_id, events)
    collection.find(_id: user_id).upsert('$push' =&gt; { events: { '$each' =&gt; events } })
  end

  def self.events_from(object_ids, type)
    Array(object_ids).map do |object_id|
      {
        't' =&gt; type,
        'o' =&gt; object_id
      }
    end
  end

  # collection storing notifications for the given day
  def self.collection(date = Date.today)
    Mongoid.default_session.with(safe: false)[collection_name(date)]
  end

  def self.collection_name(date)
    "notifications_#{date.to_s(:number)}"
  end

end
</code></pre>

<p>Here's how the <code>after_save</code> callback looks now:</p>

<pre><code class="ruby">def notify_published
  NotificationService.notify_many!(user_ids, self, 'ArtworkPublished') if self.published_changed? &amp;&amp; self.published
end
</code></pre>

<p>Let's take a look at what's going on here. When an artwork is published, we call <code>notify_many!</code> in the <code>NotificationService</code> module. That will determine the correct collection (keyed by the date) using the <code>collection</code> and <code>collection_name</code> helpers. We build our events stack with the <code>events_from</code> helper, and then do an <code>upsert</code> with a <code>$push</code> to either insert or update that user's events for that day. Due to the fast performance of this scheme, we also no longer have to batch notification creation. As a sample benchmark, writing this type of notification to our <a href="https://artsy.net/artist/andy-warhol">Warhol</a> followers takes under 15 seconds.</p>

<p>Ok, so we seem to have solved some of our issues: namely writing and archiving notifications is performant, and we understand the behavior of these collections as the number of users and content on the site grows. Now let's look at how we can query against this scheme in an efficient manner, and also how we can mark events as 'seen' to avoid emailing out duplicates.</p>

<a name="Marking.Notifications.as.Flushed.and.Retrieving.Notifications"></a>
<h3>Marking Notifications as Flushed and Retrieving Notifications</h3>

<p>We decided to push a <code>flushed</code> event onto the user's stack after we send out notifications, and analogously, when we are querying a user's notifications, we want to throw away notifications that occur before a <code>flushed</code> event. Here's that method, in our <code>NotificationService</code> module:</p>

<pre><code class="ruby"># Mark all events until this point "seen." Pushes a {flushed: &lt;id&gt;}
# hash on to events array.
def self.flush!(user_id, since = Date.today - 7.days)
  flushed = { 'flushed' =&gt; Moped::BSON::ObjectId.new }
  collections_since(since).each do |coll|
    coll.find(_id: user_id).update('$push' =&gt; { events: flushed })
  end
  flushed  # return "id" of flushed marker, in case useful later
end

private

def self.collections_since(date)
  (date..Date.today).map { |d| collection(d) }
end
</code></pre>

<p>Pretty simple. We push the appropriate event onto every collection that was under consideration via the <code>collections_since</code> helper. When we send out a personalized email we accumulate the last 7 day's worth of activity for you, and so after we generate/send a mail for a user, we can simply say <code>NotificationService.flush!(user)</code>. Here's how that day's notifications for me looks after the <code>flushed</code> event:</p>

<pre><code class="json">  {"_id"=&gt;"5106b619f56337db300001f8",
   "events"=&gt;[{"t"=&gt;"NearbyShow", "o"=&gt;"5338504e139b21f2a9000362"},
              {"t"=&gt;"FollowedArtistShow", "o"=&gt;"533ddba3a09a6764f60006b6"}, {"t"=&gt;"NearbyShow", "o"=&gt;"533ddba3a09a6764f60006b6"},
              {"flushed"=&gt;"5352b346b504f5f3690002fe"}]
  }
</code></pre>

<p>For the last piece of the puzzle, let's look at how we query against this scheme and compile together all notifications that are applicable for a given user:</p>

<pre><code class="ruby">module NotificationService
  NOTIFICATION_TYPES = {
    'FollowedArtistShow' =&gt; PartnerShow,
    'FollowedPartnerShow' =&gt; PartnerShow,
    'NearbyShow' =&gt; PartnerShow,
    'ArtworkPublished' =&gt; Artwork,
    'ArtworkSuggested' =&gt; Artwork
  }

  class Notification &lt; Struct.new(:type, :object_id)
    def object
      @object ||= NOTIFICATION_TYPES[type].find(object_id)
    end

    def applicable?
      object.try(:notifiable?) || false
    end
  end

# Return applicable notifications for user since given date.
def self.get(user_id, since = Date.today - 7.days)
  collections_since(since)
    .map { |coll| coll.find(_id: user_id).one }.compact
    .flat_map { |doc| doc['events'].slice_before { |ev| ev['flushed'] }.to_a.last }
    .reject { |ev| ev['flushed'] }.uniq
    .map { |ev| Notification.new(ev['t'], ev['o']) }.select(&amp;:applicable?)
end
</code></pre>

<p>We introduce a lite-weight <code>Notification</code> class that will load the object, as well as perform an additional check. We use the previously introduced <code>collections_since</code> helper to retrieve all the notification collections under consideration. We query each and build up an array of all events from a user's stack. We remove events that occurred prior to a <code>flushed</code> event in a given collection and the <code>flushed</code> events themselves. Then we actually load all the objects and return the ones that are still <code>applicable?</code>. That final <code>applicable?</code> check is to allow us to filter out content at run-time that is no longer valid. For example, if an artwork is published and the correct event is written out to users, but before the user can be notified the artwork is unpublished, this can serve as a run-time check to not include that work. <code>def notifiable?</code> can thus be implemented in the <code>Artwork</code> model like so:</p>

<pre><code class="ruby">def notifiable?
  published?
end
</code></pre>

<p>And...that's basically it! Throughout the week as partners are uploading their shows/fair booths/artworks, these records are being opportunistically written to that day's notification collection, in a performant and scalable fashion. Then when we want to send you a personalized email, we pull all your appropriate notifications via the <code>get</code> routine in our <code>NotificationService</code>, and primarily using the technique described in <a href="http://artsy.github.io/blog/2014/03/18/presenters-and-memoization-moving-logic-out-of-templates/">Presenters and Memoization</a> we make sure we cache/memoize all such data. Using the tips in <a href="http://artsy.github.io/blog/2014/03/17/ruby-helper-to-group-artworks-into-a-pinterest-style-layout-for-email/">Pinterest-style Layouts</a> and <a href="http://artsy.github.io/blog/2014/03/17/some-tips-for-email-layout-and-responsiveness/">Email Layouts and Responsiveness</a> we can render this content and support various devices/email clients. We parallelize and batch the generation/sending of our e-mails as well. This whole system, from notification generation to actually emailing users, is running successfully and smoothly in production.</p>

<a name="Next.Steps"></a>
<h3>Next Steps</h3>

<p>I think this type of infrastructure can easily be adapted to serve as a feed on a front-end or other client app. An API to serve up these notifications (AKA feed items) can be built and different feed items can then be rendered or aggregated at load-time. Simple client-side polling can even be set up to alert a user if something has happened that interests them <em>while</em> they're browsing! I think push notifications and other messaging can be handled by this system as well.</p>

<p>I'd love to hear any feedback and thoughts, and hopefully you've found this post informative and interesting. Please leave any feedback in the comments and <a href="https://github.com/artsy">follow us on Github</a>!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Building an English Auction with MongoDB]]></title>
    <link href="http://artsy.github.io/blog/2014/04/17/building-an-english-auction-with-mongodb/"/>
    <updated>2014-04-17T12:21:00-04:00</updated>
    <id>http://artsy.github.io/blog/2014/04/17/building-an-english-auction-with-mongodb</id>
    <content type="html"><![CDATA[<p>Artsy ran several successful auctions over the past few months. The first, <a href="https://artsy.net/feature/two-x-two">TWO x TWO</a>, raised hundreds of thousands of dollars for amfAR (the AIDS Research foundation), and the Dallas Museum of Art. It was followed by <a href="https://artsy.net/feature/ici-benefit-auction">Independent Curators International</a>, at which Artsy launched on-site auction projection screens, which displayed competing bids coming in online from places around the world, like Oslo and Santa Monica, in realtime. Users could place bids on the website, via the iPhone app or with one of the Artsy representatives in the room carrying an iPad.  All the auction lots sold, and Artsy helped ICI to raise 50% more than its target revenue goal. Other, recent Artsy auctions include <a href="https://artsy.net/feature/public-art-fund-2014-spring-benefit">Public Art Fund</a> and the <a href="https://artsy.net/feature/brooklyn-artists-ball">Brooklyn Artists Ball</a>, benefitting the Brooklyn Museum.</p>

<p><img src="/images/2014-04-17-implementing-bidding-in-an-english-auction-with-mongodb/ici-live-auction.jpg" alt="ICI Auction: Live" /></p>

<p>The domain of auctions is a fascinating one, and includes everything from buying items on eBay to trading livestock and selling investment products on the stock exchange. For those interested in the large spectrum of auctions I highly recommend <a href="http://www.sci.brooklyn.cuny.edu/~parsons/projects/mech-design/publications/bluffers-final.pdf">Auctions and bidding: A guide for computer
scientists</a> by Simon Parsons (CUNY), Juan A. Rodriguez-Aguilar (CSIC) and Mark Klein (MIT).</p>

<p>At Artsy we implemented a classic English auction with, so called, "book bids". I spent a fair amount of time visiting engineering teams that have built internet auctions, most of which were transactional systems where taking a position on an item involved starting a transaction, running an auction round and committing the changes. In contrast, we chose to deliver a simpler, eventually consistent system on top of MongoDB, in which all data is immutable and where some level of serialization occurs within a single background process.</p>

<p>In this post we'll go over some data modeling and examine the auction engine implementation details.</p>

<!-- more -->


<a name="Data.Modeling"></a>
<h3>Data Modeling</h3>

<p>In the Artsy platform, an <em>Auction</em> is an specialization of a more general concept of a <em>Sale</em>. A sale typically has an opening and a closing date, during which bidding or purchases can occur. We create a relationship between an artwork and a sale, which, in the case of an auction, includes the opening bid amount. We store all money in cents, and assume the currency to be USD, making it easy to extend the system for other currencies in the future.</p>

<pre><code class="ruby">class SaleArtwork
  include Mongoid::Document

  field :opening_bid_cents, type: Integer

  belongs_to :artwork, inverse_of: nil
  belongs_to :sale

  belongs_to :highest_bid, class_name: "Bid", inverse_of: nil

  # Minimum next acceptable bid amount, in cents.
  def minimum_next_bid_cents
    return opening_bid_cents if highest_bid.nil? &amp;&amp; opening_bid_cents.present?
    # calculate using a bid incrementing strategy ...
  end
end
</code></pre>

<p>A user registers to bid and creates a <em>Bidder</em> record.</p>

<pre><code class="ruby">class Bidder
  include Mongoid::Document

  belongs_to :user
  belongs_to :sale

  has_many :positions, class_name: 'BidderPosition', inverse_of: :bidder
end
</code></pre>

<p>This doesn't just mimic the real world where bidding typically requires registration - the bidder record doesn't belong to the user and contains essential data to identify an individual that is placing a bid. It also solves a very peculiar problem where a user decides to delete their account mid-auction. Finally, a bidder could eventually delegate bidding to an agent through this model's permissions.</p>

<p>A bidder doesn't actually place any bids, but create a <em>Bidder Position</em>, which indicates the highest amount they are willing to pay for a given artwork.</p>

<pre><code class="ruby">class BidderPosition
  include Mongoid::Document

  field :active, type: Boolean, default: true
  field :max_bid_amount_cents, type: Integer

  belongs_to :bidder, class_name: 'Bidder', inverse_of: :positions
  belongs_to :sale_artwork
  has_many :bids, inverse_of: :position

  scope :active, where(active: true).asc(:max_bid_amount_cents)
end
</code></pre>

<p>This is called a "book bid" - before technology took over the auctions world buyers delegated an agent to bid on their behalf after giving them a maximum amount they were willing to part with. Bidder positions belong to a bidder and to the artwork-to-sale relationship. They cannot be changed - if a user wants to increase his maximum bid, he simply creates a new bidder position.</p>

<a name="Bidding.Round"></a>
<h3>Bidding Round</h3>

<p>Every time a bidder position is created, a <em>Bidding Round</em> is queued for the item being bid on. We can parallelize execution of these by artwork, however all bidding rounds for the same artwork are serialized.</p>

<pre><code class="ruby">class EnglishAuction
  # Run multiple rounds of bidding for the given lot, to rest. Return number of bids generated.
  def self.run!(sale_artwork)
    return 0 unless sale_artwork.sale &amp;&amp; sale_artwork.sale.biddable?

    round = EnglishAuction::Round.new(sale_artwork)
    round.run!

    round.bids_generated.size
  end
end
</code></pre>

<p>A bidding round iterates over all active bidder positions in ascending order by dollar value, outbids any bidders below the max bid, and places new bids, as necessary. The entire round algorithm is below.</p>

<pre><code class="ruby"># A bidding round for an English auction.
class Round
  attr_accessor :bids_generated

  # @param sale_artwork A relationship between an artwork and a sale.
  def initialize(sale_artwork)
    @sale_artwork = sale_artwork
    @bids_generated = []
  end

  # Run multiple rounds of bidding, to rest.
  def run!
    while (bids = process_more_bids!).any? do
      @bids_generated += bids
    end
  end

  # Run one round of bidding. Return bids.
  def process_more_bids!
    @sale_artwork.bidder_positions.active.map do |bidder_position|
      process_bidder_position!(bidder_position)
    end.compact
  end

  # Process a single bid position.
  # @returns Generated bid, if any.
  def process_bidder_position!(bidder_position)

    # ignore if current position is highest
    return nil if bidder_position == @sale_artwork.highest_bid.try(:position)

    # ignore if bidder is already highest
    return nil if bidder_position.bidder == @sale_artwork.highest_bid.try(:position).try(:bidder)

    # close if below opening bid
    if bidder_position.max_bid_amount_cents &lt; (@sale_artwork.opening_bid_cents || 1)
      bidder_position.deactivate! "Bid must be greater than the minimum bid of #{@sale_artwork.opening_bid_cents}."
      return nil
    end

    amount_cents = @sale_artwork.minimum_next_bid_cents # opening bid or an increment thereafter

    if bidder_position.max_bid_amount_cents &lt; amount_cents
      highest_bid_amount = @sale_artwork.highest_bid.try(:amount_cents) || 0

      # if max is between current and increment (or if it's at current, but earlier), bid max anyway
      # this means that a bidder who placed an identical max bid earlier becomes the highest bidder
      if bidder_position.max_bid_amount_cents &gt; highest_bid_amount ||
        (bidder_position.max_bid_amount_cents == highest_bid_amount &amp;&amp; bidder_position.id &lt; @sale_artwork.highest_bid.position.id)
        amount_cents = bidder_position.max_bid_amount_cents
      else
        # outbid, next bid must be at least amount_cents
        bidder_position.update_attributes! active: false
        return nil
      end
    end

    # place a bid
    bidder_position.bids.create!(attrs).tap do |bid|
      @sale_artwork.update_attributes! highest_bid: bid
    end
  end
end
</code></pre>

<p>One of the interesting aspects of this system is what happens when two users create two identical bidder positions - the earlier one wins and the later one is outbid. In a transactional system we could produce an error message to the second bidder before the position is even created.</p>

<a name="Bidder.Notifications"></a>
<h3>Bidder Notifications</h3>

<p>Notifying upon being "outbid" is straightforward, because a position only enters that state once, but notifying bidders of when they are the current high bidder or when their bid has been increased is trickier. We don't want to generate notifications every time a bid is made (i.e., it's the current high). Rather, we want to allow the round to reach a stable state at which there's only a single active position and then notify the current high and outbid bidders. This happens after each <code>round.run!</code>.</p>

<a name="Beyond.Bidding"></a>
<h3>Beyond Bidding</h3>

<p>Aside of the bidding implementation we've built a whole software ecosystem around auctions. We developed a backend system to manage these. We put up projection screens at the event that list works being auctioned and flash every time a bid is placed. We register users' credit cards and collect their money.</p>

<p>The software part, however, is definitely dwarfed by the amount of logistics and people involved in making one of those auctions a success. We're only trying to make that a bit more efficient. We'll see you at the upcoming BAM Art Auction, SFMOMA Modern Ball or the Whitney Museum Art Party!</p>
]]></content>
  </entry>
  
</feed>
